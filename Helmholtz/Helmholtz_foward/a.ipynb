{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda:0\n",
      "Current loss: tensor(4485.6792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4485.4785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3341.8252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2588.3145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(857161.2500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(145751.6875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(65999.0781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8302.5137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6198.7310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5285.2939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4474.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2614.6729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1966.8596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1554.9410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1222.4316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(977.2770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(771.2332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(531.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(391.3234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(345.9613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(296.4748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(295.8928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(254.0228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(224.9318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(203.7816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(176.9812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(161.8150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(143.2786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(124.4332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(111.5419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(106.3862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(99.3494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(87.7821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(70.9712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(56.7554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(52.0714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(48.4666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(43.7983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(36.2000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(30.4368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(32.0064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(31.4875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(30.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(29.2518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(28.4051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(27.5404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(26.7434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(26.3087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(25.6775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(24.7307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(23.6057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(22.4097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(21.4211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(20.9997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(20.4628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(19.8548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(19.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(18.7111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(18.3964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(17.9788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(18.4747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(18.2963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(18.1981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(17.8936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(17.6434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(17.3670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(17.0858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(16.8419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(16.6887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(16.4758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(16.1925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(15.9696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(15.8014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(15.5301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(15.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(15.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(14.8362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(14.7311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(14.5596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(14.2970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(13.9932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.9017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.7707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.6293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.4990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.3477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.1145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.0131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.9536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.8835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.7793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.6553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.5239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.3966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.3216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.2341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.1413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.0560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.9273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(12.1635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.1102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.0796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.0467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.0146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.9792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.8797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.7971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.7294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.6461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.5681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.5021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.4451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.3874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.3139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.9663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(11.2131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.9619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.9015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.8489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.8132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.7777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.7464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.6672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.5978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.4933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.3974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.2993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(11.3792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.3277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.3078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.2711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.2411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.2096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.9999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.8873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.8088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.7479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.6989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.6522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.5920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.4910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.3865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.2851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.2010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(10.2699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.2223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.1887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.0236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.9767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.9323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.8817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.8284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.7670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.7003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.6307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.5826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.5238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.4613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.4039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.3464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.2755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(9.3290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.2837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.2602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.0712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.9502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.8816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.8261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.7945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.7598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.6676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.6136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.5728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.5332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.4979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.4644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.4289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(8.4689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.4394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.4255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.3996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.3753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.3489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.3191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.2854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.2460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.2002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.1652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.1414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.1178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.0928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.0642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.0330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.9906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.9198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.8510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.7924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(7.8343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.7973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.7647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.7429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.7304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.6913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.6416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.6089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.5839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.5514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.5196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.5002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.4715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.4320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(7.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.8685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(7.3744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(7.1745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.8804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.8447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.8158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.7913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.7723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.7510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.6682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.6288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.5954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(6.2545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.2250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.2093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.7929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.7563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(6.5294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.4993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.4810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.4697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.4467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.4136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.3831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.3512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.2856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(5.6968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(5.7892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.7392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.7015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(5.5221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.1858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.1324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(5.4059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.1524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.0913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.0555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.0127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.9822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.9612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.9411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.9162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.8945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.8817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.8712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.8604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(4.6452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(4.7039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.7997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.7061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(4.5201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.2882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(4.1309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.1227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.1151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.1026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(4.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.1030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(4.0474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(3.9368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(3.7115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(3.5306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 1 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(3.5482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(3.4608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(3.5277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(3.2164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(3.2506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(3.3124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(3.1049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(3.2501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(3.1145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(2.8441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(2.6574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(2.7789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(2.5950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(2.7242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(2.5964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(2.4637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(2.4496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(2.4074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(2.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(2.3519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(2.3851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(2.4096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(2.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(2.1653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(2.0921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(2.2945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(2.1572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.9434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(2.1440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(2.0709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 2 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(2.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.9053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.8433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.9200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(2.0447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.9909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.8819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.8042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.7883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.8085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(1.6972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.6087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.6850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.7630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(1.7714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(1.6611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.7283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(1.6808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(1.7511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(1.6423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(1.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.6022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(1.6177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(1.5819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(1.5543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(1.5973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.5786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.6169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(1.5671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 3 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.6012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.5335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.6139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.4840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(1.4514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.5282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.5738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.5371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.5382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.4582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.4527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(1.4648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.4759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.5059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.5260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(1.5472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(1.4212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.5360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(1.5180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(1.4408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(1.4352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(1.4585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.5776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(1.3452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(1.4081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(1.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(1.4557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.3917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.4831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(1.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 4 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.4843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.4262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.4293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.3446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(1.3701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.3114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.4579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.3660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.4511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.3751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.3118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(1.3485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.3433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.3037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.3367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(1.3104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(1.3008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.3197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(1.2894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(1.4070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(1.4135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(1.3159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.2987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(1.2753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(1.2591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(1.2689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(1.2376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.3903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.2579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(1.3043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 5 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.2893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.3178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.3134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(1.2459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.1755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.3367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.3160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.1795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.2686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.2310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(1.2090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.1229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.1995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.2658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(1.2334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(1.3147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.1145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(1.1935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(1.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(1.2412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(1.1574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.1693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(1.1772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(1.1818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(1.2176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(1.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.1633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.2458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(1.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 6 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.1191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.1812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.1801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(1.1452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.1291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.1968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.1454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.1202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.1374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(1.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.1666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.0316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(1.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(1.1035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.0273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(1.1605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(1.1263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(1.1212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(1.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.0746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(1.0155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(1.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(1.1273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(1.0642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.0175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.0231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(1.1072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 7 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.0875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.0683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.1159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.0358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(1.0633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.0508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(0.9867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.0697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.0431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.0242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(0.9685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.0650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.0226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(0.9794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(0.9917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.0449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(0.9823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(0.9494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(0.9986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(0.9997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.0469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(0.9818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(0.9398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(0.9410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(0.9909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(0.9544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.0352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(0.9429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 8 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.0460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(0.9285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(0.9615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(0.8998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(0.8936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.1005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(0.9845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(0.9135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(0.9118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(0.9312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(0.9886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(0.9281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(0.9707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(0.9281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(0.9265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(0.9000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(0.9277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(0.9615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(0.9227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(0.9242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(0.9588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(0.9188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(0.9349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(0.9052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(0.9366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(0.9130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(0.9309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 9 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(0.9028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(0.9725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(0.9240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(0.8865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(0.9699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(0.8629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(0.8719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(0.8706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(0.8859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(0.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(0.8725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(0.8230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(0.8733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(0.8326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(0.9441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(0.8782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(0.8186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(0.9216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(0.8640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(0.8475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(0.8304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(0.8742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(0.8667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 10 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(0.8205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(0.8233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(0.8475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(0.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(0.8960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 99\u001b[0m\n\u001b[0;32m     97\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m     98\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 99\u001b[0m     \u001b[43mPINNsModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been used in training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m((epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m, in \u001b[0;36mPINNs.train\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     68\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimiser \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mLBFGS(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr)\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\optim\\lbfgs.py:438\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter \u001b[38;5;241m!=\u001b[39m max_iter:\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;66;03m# re-evaluate function only if not in last iteration\u001b[39;00m\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;66;03m# the reason we do this: in a stochastic setting,\u001b[39;00m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;66;03m# no use to re-evaluate that function here\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 438\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    439\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[0;32m    440\u001b[0m     opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[1], line 66\u001b[0m, in \u001b[0;36mPINNs.train.<locals>.closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(inputs)\n\u001b[0;32m     65\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_func(inputs, outputs)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCurrent loss:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimiser\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     68\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\_tensor.py:426\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    423\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[0;32m    424\u001b[0m     )\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\_tensor_str.py:636\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    635\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\_tensor_str.py:567\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    565\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    566\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    570\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\_tensor_str.py:327\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    325\u001b[0m     )\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mne\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "PINNs的pytorch实现\n",
    "基本方法一致，不同的问题仅需在类中更换不同的网络、待求参数、优化算法以及损失函数\n",
    "'''\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"    #若需要使用CPU训练，去掉此行首部注释符号'#'即可\n",
    "print(\"Training device:\", device)\n",
    "\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = 300\n",
    "\n",
    "a = 1.0\n",
    "b = 100.0\n",
    "l = 1.0\n",
    "\n",
    "#定义神经网络类\n",
    "class PINNs(nn.Module):\n",
    "    def __init__(self):\n",
    "        #初始化pytorch父类\n",
    "        super().__init__()\n",
    "        #定义网络各层\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 3000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(3000, 3000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(3000, 1)\n",
    "        )\n",
    "        #定义优化器\n",
    "        self.lr = 0.5\n",
    "        self.optimiser = torch.optim.LBFGS(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs)\n",
    "\n",
    "    def loss_func(self, inputs, outputs):\n",
    "        self.u_t_x = torch.autograd.grad(outputs=outputs, inputs=inputs, grad_outputs=torch.ones_like(outputs), retain_graph=True, create_graph=True, only_inputs=True, allow_unused=True)[0]\n",
    "        self.u_tt_xx = torch.autograd.grad(outputs=self.u_t_x, inputs=inputs, grad_outputs=torch.ones_like(self.u_t_x), retain_graph=True, create_graph=True, only_inputs=True, allow_unused=True)[0]\n",
    "        self.temp_1 = torch.tensor([[1.0], [0.0]], requires_grad=True).to(device)\n",
    "        self.temp_2 = torch.tensor([[0.0], [1.0]], requires_grad=True).to(device)\n",
    "        self.f = torch.mm(self.u_tt_xx, self.temp_1)-((a**2)*torch.mm(self.u_tt_xx, self.temp_2))-(b*torch.sinh(torch.mm(inputs, self.temp_2)))\n",
    "        self.temp_3 = torch.tensor([[1.0, 0.0], [0.0, 0.0]], requires_grad=True).to(device)\n",
    "        self.temp_4 = torch.tensor([[0.0, 0.0], [0.0, 1.0]], requires_grad=True).to(device)\n",
    "        self.u_xtozero = torch.mm(inputs, self.temp_3)\n",
    "        self.u_xtol = torch.mm(inputs, self.temp_3)+torch.mm(torch.full([BATCH_SIZE, 2], l, requires_grad=True).to(device), self.temp_4)\n",
    "        self.u_ttozero = torch.mm(inputs, self.temp_4)\n",
    "        self.u_t_x_ttozero = torch.autograd.grad(outputs=self.model(self.u_ttozero), inputs=self.u_ttozero, grad_outputs=torch.ones_like(self.model(self.u_ttozero)), retain_graph=True, create_graph=True, only_inputs=True, allow_unused=True)[0]\n",
    "        self.MSE = (self.f).pow(2)+(self.model(self.u_xtozero)).pow(2)+(self.model(self.u_xtol)).pow(2)+(self.model(self.u_ttozero)).pow(2)+(torch.mm(self.u_t_x_ttozero, self.temp_1)).pow(2)\n",
    "        return self.MSE\n",
    "\n",
    "    def train(self, inputs):\n",
    "        def closure():\n",
    "            outputs = self.forward(inputs)\n",
    "            loss = self.loss_func(inputs, outputs).mean()\n",
    "            print(\"Current loss:\", loss)\n",
    "            self.optimiser.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            return loss\n",
    "        self.optimiser.step(closure)\n",
    "        self.optimiser = torch.optim.LBFGS(self.parameters(), lr=self.lr)\n",
    "\n",
    "#生成训练集\n",
    "temptrainlist=[]\n",
    "    #内部取样点\n",
    "for i in range(0, 6000):\n",
    "    t = random.uniform(0, 2)\n",
    "    x = random.uniform(0, l)\n",
    "    temptrainlist.append([t, x])\n",
    "    #三侧边缘随机取样点\n",
    "for i in range(0, 1000):\n",
    "    t = random.uniform(0, 2)\n",
    "    temptrainlist.append([t, 0])\n",
    "for i in range(0, 1000):\n",
    "    t = random.uniform(0, 2)\n",
    "    temptrainlist.append([t, l])\n",
    "for i in range(0, 1000):\n",
    "    x = random.uniform(0, l)\n",
    "    temptrainlist.append([0, x])\n",
    "trainlist = torch.tensor(temptrainlist, requires_grad=True)\n",
    "train_loader = Data.DataLoader(dataset=trainlist, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "#开始训练\n",
    "PINNsModel = PINNs().to(device)\n",
    "for epoch in range(1, EPOCH+1):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        torch.cuda.empty_cache()\n",
    "        data = data.to(device)\n",
    "        PINNsModel.train(data)\n",
    "        print(\"Batch\", i, \"has been used in training\")\n",
    "    if((epoch % 50) == 0):\n",
    "        PINNsModel.lr *= 0.9\n",
    "    print(\"Epoch\", epoch, \"has finished, and the current learning rate is\", PINNsModel.lr)\n",
    "torch.save(PINNsModel.state_dict(), \"./wave equation net.pkl\")\n",
    "\n",
    "#编写目标函数解析式及绘图\n",
    "def u(t, x):\n",
    "    temp = 0.0\n",
    "    for n in range(1, 1001):\n",
    "        temp += (((-1)**(n+1))*(math.sin((n*(math.pi)*x)/l))*(1-math.cos((a*n*(math.pi)*t)/l)))/(n*((n**2)*((math.pi)**2)+(l**2)))\n",
    "    return ((2.0*b*(l**2))*(math.sinh(l))*temp)/((a**2)*(math.pi))\n",
    "x_slice = 100\n",
    "y_slice = 100\n",
    "t = np.linspace(0, 2, x_slice, dtype=np.float32)\n",
    "x = np.linspace(0, 1, y_slice, dtype=np.float32)\n",
    "T, X = np.meshgrid(t, x)\n",
    "Z = np.array(np.arange(0, 1, (1.0/(x_slice*y_slice)))).reshape(x_slice, y_slice)\n",
    "for i in range(0, x_slice):\n",
    "    for j in range(0, y_slice):\n",
    "        Z[i][j] = u(T[i][j], X[i][j])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(T, X, Z, cmap=cm.YlGnBu_r)\n",
    "plt.savefig(\"wave equation[exact solution].pdf\")\n",
    "\n",
    "#绘制拟合函数图像并创建测试集对比训练结果与目标函数的差异\n",
    "x_slice = 100\n",
    "y_slice = 100\n",
    "t = np.linspace(0, 2, x_slice, dtype=np.float32)\n",
    "x = np.linspace(0, 1, y_slice, dtype=np.float32)\n",
    "T, X = np.meshgrid(t, x)\n",
    "Z = np.array(np.arange(0, 1, (1.0/(x_slice*y_slice)))).reshape(x_slice, y_slice)\n",
    "for i in range(0, x_slice):\n",
    "    for j in range(0, y_slice):\n",
    "        temp = torch.tensor([T[i][j], X[i][j]], requires_grad=True).to(device)\n",
    "        Z[i][j] = PINNsModel.forward(temp).tolist()[0]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(T, X, Z, cmap=cm.YlGnBu_r)\n",
    "plt.savefig(\"wave equation[fitting solution].pdf\")\n",
    "error = []\n",
    "for i in range(1, 10001):\n",
    "    t = random.uniform(0, 2)\n",
    "    x = random.uniform(0, l)\n",
    "    temp = torch.tensor([t, x], requires_grad=True).to(device)\n",
    "    error.append((PINNsModel.forward(temp).tolist()[0]-u(t, x))**2)\n",
    "print(\"Mean squared error of the model:\", np.mean(error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
