{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training device: cuda:0\n",
      "Current loss: tensor(4485.6792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4485.4785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3341.8252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2588.3145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(857161.2500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(145751.6875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(65999.0781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8302.5137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6198.7310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5285.2939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4474.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2614.6729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1966.8596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1554.9410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1222.4316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(977.2770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(771.2332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(531.2151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(391.3234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(345.9613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(296.4748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(295.8928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(254.0228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(224.9318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(203.7816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(176.9812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(161.8150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(143.2786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(124.4332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(111.5419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(106.3862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(99.3494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(87.7821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(70.9712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(56.7554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(52.0714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(48.4666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(43.7983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(36.2000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(30.4368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(32.0064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(31.4875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(30.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(29.2518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(28.4051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(27.5404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(26.7434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(26.3087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(25.6775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(24.7307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(23.6057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(22.4097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(21.4211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(20.9997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(20.4628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(19.8548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(19.2052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(18.7111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(18.3964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(17.9788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(18.4747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(18.2963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(18.1981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(17.8936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(17.6434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(17.3670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(17.0858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(16.8419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(16.6887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(16.4758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(16.1925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(15.9696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(15.8014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(15.5301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(15.2195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(15.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(14.8362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(14.7311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(14.5596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(14.2970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(13.9932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.9017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.7707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.6293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.4990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.3477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.1145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(13.0131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.9536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.8835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.7793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.6553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.5239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.3966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.3216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.2341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.1413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.0560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.9273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(12.1635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.1102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.0796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.0467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(12.0146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.9792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.8797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.7971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.7294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.6461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.5681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.5021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.4451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.3874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.3139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.9663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(11.2131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.9619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.9015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.8489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.8132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.7777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.7464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.7133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.6672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.5978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.4933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.3974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.2993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(11.3792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.3277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.3078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.2711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.2411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.2096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.1171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(11.0282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.9999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.8873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.8088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.7479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.6989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.6522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.5920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.4910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.3865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.2851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.2010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(10.2699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.2223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.1887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.1523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(10.0236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.9767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.9323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.8817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.8284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.7670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.7003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.6307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.5826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.5238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.4613, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.4039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.3464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.2755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(9.3290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.2837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.2602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.0712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(9.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.9502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.8816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.8261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.7945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.7598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.7149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.6676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.6136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.5728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.5332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.4979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.4644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.4289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(8.4689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.4394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.4255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.3996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.3753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.3489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.3191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.2854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.2460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.2002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.1652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.1414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.1178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.0928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.0642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(8.0330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.9906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.9198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.8510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.7924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(7.8343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.7973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.7647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.7429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.7304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.6913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.6416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.6089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.5839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.5514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.5196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.5002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.4715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.4320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(7.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.8685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(7.3744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.3080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.2008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(7.1745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.1033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(7.0257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.9400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.8804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.8447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.8158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.7913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.7723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.7510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.6682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.6288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.5954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(6.2545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.2250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.2093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.7929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.7563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(6.5294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.4993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.4810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.4697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.4467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.4136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.3831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.3512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.2856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.1410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(6.0181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.9005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(5.6968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(5.7892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.8181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.7392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.7015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.6133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.5007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(5.5221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.4071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.1858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.1324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(5.4059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.3086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.1524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.0913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.0555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(5.0127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.9822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.9612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.9411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.9162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.8945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.8817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.8712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.8604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(4.6452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(4.7039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.7997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.7061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.6034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(4.5201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.5047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.4202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.2882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(4.1309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.1227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.1151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.1026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(4.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.1030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(4.0474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(4.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(3.9368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.9103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.8084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(3.7115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.6095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(3.5306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.7126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 1 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(3.5482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(3.4608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(3.5277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.5093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(3.2164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(3.2506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.4894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(3.3124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(3.1049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(3.2501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.3626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.2024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(3.1145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(3.0085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.9336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(2.8441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.8075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(2.6574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(2.7789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.7039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(2.5950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(2.7242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(2.5964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.6223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(2.4637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.5071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(2.4496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(2.4074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(2.2483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(2.3519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(2.3851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(2.4096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.4090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.3032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(2.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(2.1653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0994, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(2.0921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(2.2945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(2.1572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.2965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.9434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(2.1440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.1027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(2.0709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 2 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(2.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.9053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.8433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.9200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(2.0447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(2.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.9909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.8819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.8042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.7883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.8085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.8009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(1.6972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.6087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.6850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.7630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(1.7714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(1.6611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.7283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(1.6808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(1.7511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(1.6423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(1.7188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.6022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(1.6177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(1.5819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.9064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(1.5543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.7426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5354, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(1.5973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.5786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.6169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(1.5671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 3 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.6012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.5335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.6139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.4840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4576, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(1.4514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.5282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.5738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.5371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.5382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.4582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.4527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(1.4648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.4759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.5059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4721, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.5260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(1.5472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(1.4212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.5360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(1.5180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(1.4408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(1.4352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(1.4585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.5776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(1.3452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(1.4081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(1.3562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(1.4557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.3917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.4831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(1.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 4 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.4843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.6011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.5103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.4262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.4293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.3446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(1.3701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.3114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.4579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.3660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.4511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.3751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.3118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(1.3485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3153, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.3433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.3037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.3367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(1.3104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(1.3008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.3197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2797, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(1.2894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(1.4070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(1.4135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(1.3159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2955, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.2987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(1.2753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(1.2591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(1.2689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2300, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(1.2376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2287, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2143, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.3903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.4030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.2579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(1.3043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 5 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.2893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.3178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.3134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(1.2459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1951, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.1755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.3367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2760, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.3160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.1795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.2686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.2310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(1.2090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.1229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0940, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.1995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.2658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(1.2334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(1.3147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.1145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(1.1935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(1.2212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2012, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(1.2412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1975, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(1.1574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1367, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.1693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(1.1772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(1.1818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(1.2176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(1.1001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0938, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0434, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.1633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.2458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.3433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(1.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 6 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.1191, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.1812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.1564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.2231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1646, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.1801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(1.1452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1138, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.1291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1286, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0732, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.1968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.1454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.1202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.1374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(1.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.1666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.0316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0106, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.0993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(1.1569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(1.1035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.0273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(1.1605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1522, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(1.1263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1064, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0724, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(1.1212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0989, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0860, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(1.1101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.0746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(1.0155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9912, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9906, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(1.1365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(1.1273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1112, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0871, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(1.0642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0610, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0500, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(1.0175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.0231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0690, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0060, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(1.1072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0670, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 7 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.0875, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0520, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.0683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0604, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0319, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(1.1159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(1.0358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0086, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(1.0633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0381, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(1.0508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0283, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9999, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9920, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(0.9867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(1.0697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0834, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0583, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(1.0431, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(1.0242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0223, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9979, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(0.9685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9533, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9502, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(1.1068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.1027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(1.0650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0556, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(1.0226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9758, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(0.9794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9837, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9518, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(0.9917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(1.0449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0387, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0360, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0341, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(0.9823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9773, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9740, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(0.9494, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9359, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9347, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9313, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9282, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(0.9986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0014, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9962, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9712, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9688, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(0.9997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9898, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9809, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9780, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(1.0469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0196, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(0.9818, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9713, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9681, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(0.9398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9351, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9235, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9194, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(0.9410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9365, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9318, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9269, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(0.9909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9833, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(0.9544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9266, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(1.0352, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9923, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9909, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9844, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(0.9429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9353, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9126, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 8 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(1.0460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0345, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0193, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(1.0464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0338, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0169, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(0.9285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8829, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8784, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(0.9615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9517, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9291, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9244, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9207, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(0.8998, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8903, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8887, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(0.8936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8826, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8599, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(1.1005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0600, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(1.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9808, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(0.9845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9328, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(0.9135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8973, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8812, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8803, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8793, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(0.9118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8937, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8814, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8737, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(0.9312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(0.9886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9849, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9795, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9749, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9736, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9598, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(0.9281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9311, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9212, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9160, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9141, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(0.9707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9694, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9425, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(0.9281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9221, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(0.9265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(0.9000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8870, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8827, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(0.9277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9241, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9213, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9171, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(0.9615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9531, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9490, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9340, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9234, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(0.9227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8965, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(0.9242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9085, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8996, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(0.9588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9508, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9427, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9397, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(0.9188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9146, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8945, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8934, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8924, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8908, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(0.9349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9334, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9290, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(0.9052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8941, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8763, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8744, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(0.9366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9263, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8974, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8853, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(0.9130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8901, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8878, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8851, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8922, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(0.9309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8767, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8748, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8727, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8700, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8674, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 9 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(0.9028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8947, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8880, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8802, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8753, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(0.9725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(1.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(0.9240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9083, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9000, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8954, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8928, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(0.8865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8805, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8761, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8659, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8634, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(0.9699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9330, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8514, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8344, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8114, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7990, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(0.8629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8584, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8558, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8486, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8455, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8601, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(0.8719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8668, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8606, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8593, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8566, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8460, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8457, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8454, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8448, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8440, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 9 has been used in training\n",
      "Current loss: tensor(0.8706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9350, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8669, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8664, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8651, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8575, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 10 has been used in training\n",
      "Current loss: tensor(0.8859, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8776, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8698, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8665, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8607, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8587, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8535, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 11 has been used in training\n",
      "Current loss: tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8430, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8364, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 12 has been used in training\n",
      "Current loss: tensor(0.9474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9487, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9322, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 13 has been used in training\n",
      "Current loss: tensor(0.8725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8885, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8636, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8456, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 14 has been used in training\n",
      "Current loss: tensor(0.8230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8001, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 15 has been used in training\n",
      "Current loss: tensor(0.8733, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8662, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8655, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8647, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8534, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 16 has been used in training\n",
      "Current loss: tensor(0.8326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8224, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8211, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8206, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8195, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 17 has been used in training\n",
      "Current loss: tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8564, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8449, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 18 has been used in training\n",
      "Current loss: tensor(0.9441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9260, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9184, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9162, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9010, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8986, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 19 has been used in training\n",
      "Current loss: tensor(0.8782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8848, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8729, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8559, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 20 has been used in training\n",
      "Current loss: tensor(0.8186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7929, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 21 has been used in training\n",
      "Current loss: tensor(0.9216, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9119, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8946, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8919, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 22 has been used in training\n",
      "Current loss: tensor(0.8640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8704, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8588, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8530, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 23 has been used in training\n",
      "Current loss: tensor(0.8475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8369, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8298, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8275, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8258, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 24 has been used in training\n",
      "Current loss: tensor(0.8304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8210, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7949, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7925, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7899, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7869, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 25 has been used in training\n",
      "Current loss: tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7916, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7772, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 26 has been used in training\n",
      "Current loss: tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8417, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8259, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8249, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 27 has been used in training\n",
      "Current loss: tensor(0.8742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8157, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8070, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 28 has been used in training\n",
      "Current loss: tensor(0.8667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8492, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8402, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8363, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 29 has been used in training\n",
      "Epoch 10 has finished, and the current learning rate is 0.5\n",
      "Current loss: tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8333, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8273, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8151, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 0 has been used in training\n",
      "Current loss: tensor(0.8205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8174, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7977, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 1 has been used in training\n",
      "Current loss: tensor(0.8233, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7957, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 2 has been used in training\n",
      "Current loss: tensor(0.8475, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8423, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8403, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8293, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8280, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8238, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 3 has been used in training\n",
      "Current loss: tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8006, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7673, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 4 has been used in training\n",
      "Current loss: tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8804, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8657, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8616, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8602, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8589, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8582, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8574, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8510, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 5 has been used in training\n",
      "Current loss: tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8551, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8383, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8265, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8246, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8242, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8237, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8231, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 6 has been used in training\n",
      "Current loss: tensor(0.8524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8499, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8489, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8483, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8459, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8409, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8401, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8394, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8368, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 7 has been used in training\n",
      "Current loss: tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7718, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Batch 8 has been used in training\n",
      "Current loss: tensor(0.8960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8706, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8453, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "Current loss: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 99\u001b[0m\n\u001b[0;32m     97\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m     98\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 99\u001b[0m     \u001b[43mPINNsModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch\u001b[39m\u001b[38;5;124m\"\u001b[39m, i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been used in training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m((epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m, in \u001b[0;36mPINNs.train\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     68\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimiser \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mLBFGS(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr)\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\optim\\lbfgs.py:438\u001b[0m, in \u001b[0;36mLBFGS.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter \u001b[38;5;241m!=\u001b[39m max_iter:\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;66;03m# re-evaluate function only if not in last iteration\u001b[39;00m\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;66;03m# the reason we do this: in a stochastic setting,\u001b[39;00m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;66;03m# no use to re-evaluate that function here\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 438\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    439\u001b[0m     flat_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather_flat_grad()\n\u001b[0;32m    440\u001b[0m     opt_cond \u001b[38;5;241m=\u001b[39m flat_grad\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tolerance_grad\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[1], line 66\u001b[0m, in \u001b[0;36mPINNs.train.<locals>.closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(inputs)\n\u001b[0;32m     65\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_func(inputs, outputs)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m---> 66\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCurrent loss:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimiser\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     68\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\_tensor.py:426\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    423\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[0;32m    424\u001b[0m     )\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 426\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\_tensor_str.py:636\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    635\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\_tensor_str.py:567\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    565\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    566\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[0;32m    570\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\_tensor_str.py:327\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    325\u001b[0m     )\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32md:\\setup_position_1\\anaconda\\envs\\pytorch-gpu\\lib\\site-packages\\torch\\_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m&\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mne\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonzero_finite_vals\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;66;03m# no valid number, do nothing\u001b[39;00m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "PINNspytorch\n",
    "\n",
    "'''\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"    #CPU'#'\n",
    "print(\"Training device:\", device)\n",
    "\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = 300\n",
    "\n",
    "a = 1.0\n",
    "b = 100.0\n",
    "l = 1.0\n",
    "\n",
    "#\n",
    "class PINNs(nn.Module):\n",
    "    def __init__(self):\n",
    "        #pytorch\n",
    "        super().__init__()\n",
    "        #\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2, 3000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(3000, 3000),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(3000, 1)\n",
    "        )\n",
    "        #\n",
    "        self.lr = 0.5\n",
    "        self.optimiser = torch.optim.LBFGS(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.model(inputs)\n",
    "\n",
    "    def loss_func(self, inputs, outputs):\n",
    "        self.u_t_x = torch.autograd.grad(outputs=outputs, inputs=inputs, grad_outputs=torch.ones_like(outputs), retain_graph=True, create_graph=True, only_inputs=True, allow_unused=True)[0]\n",
    "        self.u_tt_xx = torch.autograd.grad(outputs=self.u_t_x, inputs=inputs, grad_outputs=torch.ones_like(self.u_t_x), retain_graph=True, create_graph=True, only_inputs=True, allow_unused=True)[0]\n",
    "        self.temp_1 = torch.tensor([[1.0], [0.0]], requires_grad=True).to(device)\n",
    "        self.temp_2 = torch.tensor([[0.0], [1.0]], requires_grad=True).to(device)\n",
    "        self.f = torch.mm(self.u_tt_xx, self.temp_1)-((a**2)*torch.mm(self.u_tt_xx, self.temp_2))-(b*torch.sinh(torch.mm(inputs, self.temp_2)))\n",
    "        self.temp_3 = torch.tensor([[1.0, 0.0], [0.0, 0.0]], requires_grad=True).to(device)\n",
    "        self.temp_4 = torch.tensor([[0.0, 0.0], [0.0, 1.0]], requires_grad=True).to(device)\n",
    "        self.u_xtozero = torch.mm(inputs, self.temp_3)\n",
    "        self.u_xtol = torch.mm(inputs, self.temp_3)+torch.mm(torch.full([BATCH_SIZE, 2], l, requires_grad=True).to(device), self.temp_4)\n",
    "        self.u_ttozero = torch.mm(inputs, self.temp_4)\n",
    "        self.u_t_x_ttozero = torch.autograd.grad(outputs=self.model(self.u_ttozero), inputs=self.u_ttozero, grad_outputs=torch.ones_like(self.model(self.u_ttozero)), retain_graph=True, create_graph=True, only_inputs=True, allow_unused=True)[0]\n",
    "        self.MSE = (self.f).pow(2)+(self.model(self.u_xtozero)).pow(2)+(self.model(self.u_xtol)).pow(2)+(self.model(self.u_ttozero)).pow(2)+(torch.mm(self.u_t_x_ttozero, self.temp_1)).pow(2)\n",
    "        return self.MSE\n",
    "\n",
    "    def train(self, inputs):\n",
    "        def closure():\n",
    "            outputs = self.forward(inputs)\n",
    "            loss = self.loss_func(inputs, outputs).mean()\n",
    "            print(\"Current loss:\", loss)\n",
    "            self.optimiser.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            return loss\n",
    "        self.optimiser.step(closure)\n",
    "        self.optimiser = torch.optim.LBFGS(self.parameters(), lr=self.lr)\n",
    "\n",
    "#\n",
    "temptrainlist=[]\n",
    "    #\n",
    "for i in range(0, 6000):\n",
    "    t = random.uniform(0, 2)\n",
    "    x = random.uniform(0, l)\n",
    "    temptrainlist.append([t, x])\n",
    "    #\n",
    "for i in range(0, 1000):\n",
    "    t = random.uniform(0, 2)\n",
    "    temptrainlist.append([t, 0])\n",
    "for i in range(0, 1000):\n",
    "    t = random.uniform(0, 2)\n",
    "    temptrainlist.append([t, l])\n",
    "for i in range(0, 1000):\n",
    "    x = random.uniform(0, l)\n",
    "    temptrainlist.append([0, x])\n",
    "trainlist = torch.tensor(temptrainlist, requires_grad=True)\n",
    "train_loader = Data.DataLoader(dataset=trainlist, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "#\n",
    "PINNsModel = PINNs().to(device)\n",
    "for epoch in range(1, EPOCH+1):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        torch.cuda.empty_cache()\n",
    "        data = data.to(device)\n",
    "        PINNsModel.train(data)\n",
    "        print(\"Batch\", i, \"has been used in training\")\n",
    "    if((epoch % 50) == 0):\n",
    "        PINNsModel.lr *= 0.9\n",
    "    print(\"Epoch\", epoch, \"has finished, and the current learning rate is\", PINNsModel.lr)\n",
    "torch.save(PINNsModel.state_dict(), \"./wave equation net.pkl\")\n",
    "\n",
    "#\n",
    "def u(t, x):\n",
    "    temp = 0.0\n",
    "    for n in range(1, 1001):\n",
    "        temp += (((-1)**(n+1))*(math.sin((n*(math.pi)*x)/l))*(1-math.cos((a*n*(math.pi)*t)/l)))/(n*((n**2)*((math.pi)**2)+(l**2)))\n",
    "    return ((2.0*b*(l**2))*(math.sinh(l))*temp)/((a**2)*(math.pi))\n",
    "x_slice = 100\n",
    "y_slice = 100\n",
    "t = np.linspace(0, 2, x_slice, dtype=np.float32)\n",
    "x = np.linspace(0, 1, y_slice, dtype=np.float32)\n",
    "T, X = np.meshgrid(t, x)\n",
    "Z = np.array(np.arange(0, 1, (1.0/(x_slice*y_slice)))).reshape(x_slice, y_slice)\n",
    "for i in range(0, x_slice):\n",
    "    for j in range(0, y_slice):\n",
    "        Z[i][j] = u(T[i][j], X[i][j])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(T, X, Z, cmap=cm.YlGnBu_r)\n",
    "plt.savefig(\"wave equation[exact solution].pdf\")\n",
    "\n",
    "#\n",
    "x_slice = 100\n",
    "y_slice = 100\n",
    "t = np.linspace(0, 2, x_slice, dtype=np.float32)\n",
    "x = np.linspace(0, 1, y_slice, dtype=np.float32)\n",
    "T, X = np.meshgrid(t, x)\n",
    "Z = np.array(np.arange(0, 1, (1.0/(x_slice*y_slice)))).reshape(x_slice, y_slice)\n",
    "for i in range(0, x_slice):\n",
    "    for j in range(0, y_slice):\n",
    "        temp = torch.tensor([T[i][j], X[i][j]], requires_grad=True).to(device)\n",
    "        Z[i][j] = PINNsModel.forward(temp).tolist()[0]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(T, X, Z, cmap=cm.YlGnBu_r)\n",
    "plt.savefig(\"wave equation[fitting solution].pdf\")\n",
    "error = []\n",
    "for i in range(1, 10001):\n",
    "    t = random.uniform(0, 2)\n",
    "    x = random.uniform(0, l)\n",
    "    temp = torch.tensor([t, x], requires_grad=True).to(device)\n",
    "    error.append((PINNsModel.forward(temp).tolist()[0]-u(t, x))**2)\n",
    "print(\"Mean squared error of the model:\", np.mean(error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
